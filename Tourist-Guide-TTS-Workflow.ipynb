{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "125d3f83",
   "metadata": {},
   "source": [
    "# Tourist Guide TTS Workflow\n",
    "\n",
    "This notebook implements a Text-to-Speech (TTS) workflow specifically designed for creating tourist guide audio recordings. Unlike podcast-style content, tourist guides require:\n",
    "\n",
    "- **Clear, informative narration** with appropriate pacing\n",
    "- **Consistent voice and tone** across multiple locations\n",
    "- **Structured content** for location descriptions, historical facts, and practical information\n",
    "- **Professional audio quality** suitable for mobile apps and tourism platforms\n",
    "\n",
    "## Workflow Overview:\n",
    "1. Install and configure TTS models\n",
    "2. Structure tourist guide content\n",
    "3. Generate audio for individual locations\n",
    "4. Process multiple locations in batch\n",
    "5. Apply audio enhancements\n",
    "6. Export with proper metadata"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b01a753",
   "metadata": {},
   "source": [
    "## 1. Install and Import Required Libraries\n",
    "\n",
    "We'll use modern TTS models that are compatible with our Python environment and suitable for clear, professional narration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42e29a6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages (run once)\n",
    "# Note: Some packages may need specific Python versions\n",
    "# !pip install torch transformers pydub scipy numpy tqdm IPython\n",
    "# !pip install TTS  # Coqui TTS - alternative to parler-tts\n",
    "# !pip install gTTS  # Google Text-to-Speech as fallback option"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af03b82c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import core libraries\n",
    "import torch\n",
    "import numpy as np\n",
    "import json\n",
    "import os\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "from datetime import datetime\n",
    "import psutil  # For system memory monitoring\n",
    "\n",
    "# Audio processing\n",
    "from pydub import AudioSegment\n",
    "from pydub.effects import normalize, compress_dynamic_range\n",
    "import io\n",
    "from scipy.io import wavfile\n",
    "\n",
    "# TTS models (we'll implement multiple options)\n",
    "from transformers import AutoProcessor, AutoTokenizer\n",
    "from IPython.display import Audio, display\n",
    "import IPython.display as ipd\n",
    "\n",
    "print(\"Libraries imported successfully!\")\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "print(f\"MPS available: {torch.backends.mps.is_available() if hasattr(torch.backends, 'mps') else False}\")\n",
    "\n",
    "# Device configuration with support for CUDA, MPS (Apple Silicon), and CPU\n",
    "def get_optimal_device():\n",
    "    \"\"\"Automatically detect and return the best available device\"\"\"\n",
    "    if torch.cuda.is_available():\n",
    "        device = \"cuda\"\n",
    "        device_name = torch.cuda.get_device_name(0)\n",
    "        print(f\"üöÄ Using NVIDIA GPU: {device_name}\")\n",
    "    elif torch.backends.mps.is_available():\n",
    "        device = \"mps\"\n",
    "        print(f\"üçé Using Apple Silicon GPU (Metal Performance Shaders)\")\n",
    "    else:\n",
    "        device = \"cpu\"\n",
    "        print(f\"üíª Using CPU (consider using GPU for faster processing)\")\n",
    "    \n",
    "    return device"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8edf55f",
   "metadata": {},
   "source": [
    "## 2. Load and Configure TTS Models\n",
    "\n",
    "We'll set up TTS models optimized for clear, engaging narration suitable for tourist guides. We'll implement multiple model options for flexibility."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74996c0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure device for TTS processing\n",
    "device = get_optimal_device()\n",
    "print(f\"Selected device: {device}\")\n",
    "\n",
    "# Model configuration for tourist guides\n",
    "TTS_CONFIG = {\n",
    "    \"voice_style\": \"professional_guide\",  # Clear, informative, friendly\n",
    "    \"speaking_rate\": \"moderate\",          # Not too fast, easy to follow\n",
    "    \"emphasis\": \"educational\",           # Suitable for learning content\n",
    "    \"language\": \"en\",                    # Can be extended for multilingual guides\n",
    "    \"device\": device,                    # Store device info\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b22731f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TTS Model Loader Class with Multi-Device Support\n",
    "class TouristGuideTTS:\n",
    "    def __init__(self, device=\"cpu\"):\n",
    "        self.device = device\n",
    "        self.model = None\n",
    "        self.processor = None\n",
    "        self.sampling_rate = None\n",
    "        \n",
    "        # Device-specific configurations\n",
    "        self.torch_dtype = self._get_optimal_dtype()\n",
    "        \n",
    "    def _get_optimal_dtype(self):\n",
    "        \"\"\"Get optimal tensor type based on device\"\"\"\n",
    "        if self.device == \"cuda\":\n",
    "            return torch.float16  # Use half precision for CUDA\n",
    "        elif self.device == \"mps\":\n",
    "            return torch.float32  # MPS works best with float32\n",
    "        else:\n",
    "            return torch.float32  # CPU uses float32\n",
    "        \n",
    "    def load_bark_model(self):\n",
    "        \"\"\"Load Suno Bark model for tourist guide narration\"\"\"\n",
    "        try:\n",
    "            from transformers import BarkModel, AutoProcessor\n",
    "            self.processor = AutoProcessor.from_pretrained(\"suno/bark\")\n",
    "            \n",
    "            print(f\"Loading Bark model on {self.device} with {self.torch_dtype}...\")\n",
    "            self.model = BarkModel.from_pretrained(\n",
    "                \"suno/bark\", \n",
    "                torch_dtype=self.torch_dtype\n",
    "            )\n",
    "            \n",
    "            # Move model to device\n",
    "            if self.device == \"mps\":\n",
    "                # For MPS, we need to be more careful with device placement\n",
    "                try:\n",
    "                    self.model = self.model.to(self.device)\n",
    "                except Exception as e:\n",
    "                    print(f\"‚ö†Ô∏è MPS placement failed, falling back to CPU: {e}\")\n",
    "                    self.device = \"cpu\"\n",
    "                    self.torch_dtype = torch.float32\n",
    "                    self.model = self.model.to(self.device)\n",
    "            else:\n",
    "                self.model = self.model.to(self.device)\n",
    "            \n",
    "            self.sampling_rate = 24000\n",
    "            self.voice_preset = \"v2/en_speaker_9\"  # Professional, clear voice\n",
    "            print(f\"‚úÖ Bark model loaded successfully on {self.device}\")\n",
    "            return True\n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Failed to load Bark model: {e}\")\n",
    "            return False\n",
    "    \n",
    "    def load_gtts_fallback(self):\n",
    "        \"\"\"Load Google TTS as fallback option\"\"\"\n",
    "        try:\n",
    "            from gtts import gTTS\n",
    "            self.gtts = gTTS\n",
    "            self.sampling_rate = 22050  # Standard for gTTS\n",
    "            print(\"‚úÖ Google TTS loaded as fallback\")\n",
    "            return True\n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Failed to load Google TTS: {e}\")\n",
    "            return False\n",
    "    \n",
    "    def generate_speech(self, text, method=\"bark\"):\n",
    "        \"\"\"Generate speech from text using specified method\"\"\"\n",
    "        if method == \"bark\" and self.model is not None:\n",
    "            return self._generate_bark_speech(text)\n",
    "        elif method == \"gtts\" and hasattr(self, 'gtts'):\n",
    "            return self._generate_gtts_speech(text)\n",
    "        else:\n",
    "            raise ValueError(f\"Method '{method}' not available or not loaded\")\n",
    "    \n",
    "    def _generate_bark_speech(self, text):\n",
    "        \"\"\"Generate speech using Bark model with device-aware processing\"\"\"\n",
    "        try:\n",
    "            inputs = self.processor(text, voice_preset=self.voice_preset)\n",
    "            \n",
    "            # Move inputs to device with proper error handling\n",
    "            if self.device == \"mps\":\n",
    "                # MPS sometimes has issues with certain operations\n",
    "                try:\n",
    "                    inputs = {k: v.to(self.device) if hasattr(v, 'to') else v for k, v in inputs.items()}\n",
    "                except Exception as e:\n",
    "                    print(f\"‚ö†Ô∏è MPS input processing failed, using CPU: {e}\")\n",
    "                    self.device = \"cpu\"\n",
    "                    self.model = self.model.to(\"cpu\")\n",
    "                    inputs = {k: v.to(\"cpu\") if hasattr(v, 'to') else v for k, v in inputs.items()}\n",
    "            else:\n",
    "                inputs = {k: v.to(self.device) if hasattr(v, 'to') else v for k, v in inputs.items()}\n",
    "            \n",
    "            # Generate with device-appropriate settings\n",
    "            with torch.inference_mode():  # More efficient than no_grad for inference\n",
    "                speech_output = self.model.generate(\n",
    "                    **inputs, \n",
    "                    temperature=0.7, \n",
    "                    semantic_temperature=0.8,\n",
    "                    do_sample=True\n",
    "                )\n",
    "            \n",
    "            audio_arr = speech_output[0].cpu().numpy()\n",
    "            return audio_arr, self.sampling_rate\n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Bark generation failed: {e}\")\n",
    "            # Fallback to CPU if there are device issues\n",
    "            if self.device != \"cpu\":\n",
    "                print(\"üîÑ Attempting generation on CPU...\")\n",
    "                self.device = \"cpu\"\n",
    "                self.model = self.model.to(\"cpu\")\n",
    "                return self._generate_bark_speech(text)\n",
    "            raise e\n",
    "    \n",
    "    def _generate_gtts_speech(self, text):\n",
    "        \"\"\"Generate speech using Google TTS\"\"\"\n",
    "        tts = self.gtts(text=text, lang='en', slow=False)\n",
    "        # Save to temporary file and load as audio\n",
    "        temp_file = io.BytesIO()\n",
    "        tts.write_to_fp(temp_file)\n",
    "        temp_file.seek(0)\n",
    "        \n",
    "        # Convert to audio array\n",
    "        audio_segment = AudioSegment.from_file(temp_file, format=\"mp3\")\n",
    "        audio_arr = np.array(audio_segment.get_array_of_samples(), dtype=np.float32)\n",
    "        if audio_segment.channels == 2:\n",
    "            audio_arr = audio_arr.reshape((-1, 2)).mean(axis=1)\n",
    "        audio_arr = audio_arr / np.max(np.abs(audio_arr))  # Normalize\n",
    "        \n",
    "        return audio_arr, audio_segment.frame_rate\n",
    "\n",
    "# Initialize TTS system with automatic device detection\n",
    "tts_system = TouristGuideTTS(device=device)\n",
    "\n",
    "# Try to load models (in order of preference)\n",
    "model_loaded = False\n",
    "if tts_system.load_bark_model():\n",
    "    model_loaded = True\n",
    "    current_tts_method = \"bark\"\n",
    "elif tts_system.load_gtts_fallback():\n",
    "    model_loaded = True\n",
    "    current_tts_method = \"gtts\"\n",
    "else:\n",
    "    print(\"‚ùå No TTS models could be loaded\")\n",
    "\n",
    "if model_loaded:\n",
    "    print(f\"üéØ TTS system ready using: {current_tts_method}\")\n",
    "    print(f\"üíæ Memory usage optimized for: {device}\")\n",
    "    if device == \"mps\":\n",
    "        print(\"üì± Apple Silicon optimizations enabled\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f569d6f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apple Silicon Optimizations and Memory Management\n",
    "def optimize_for_apple_silicon():\n",
    "    \"\"\"Apply Apple Silicon specific optimizations\"\"\"\n",
    "    if device == \"mps\":\n",
    "        print(\"üçé Applying Apple Silicon optimizations...\")\n",
    "        \n",
    "        # Check available memory\n",
    "        available_memory_gb = psutil.virtual_memory().available / (1024**3)\n",
    "        print(f\"üíæ Available RAM: {available_memory_gb:.1f} GB\")\n",
    "        \n",
    "        # Optimize PyTorch for Apple Silicon\n",
    "        torch.backends.mps.empty_cache()  # Clear MPS cache\n",
    "        \n",
    "        # Set memory management strategies\n",
    "        if available_memory_gb > 16:\n",
    "            print(\"‚úÖ High memory system detected - using full precision\")\n",
    "        elif available_memory_gb > 8:\n",
    "            print(\"‚ö†Ô∏è Medium memory system - optimizing batch sizes\")\n",
    "        else:\n",
    "            print(\"‚ö†Ô∏è Low memory system - using conservative settings\")\n",
    "            \n",
    "        # Apple Silicon specific settings\n",
    "        optimizations = {\n",
    "            \"use_mps_fallback\": True,\n",
    "            \"batch_size\": \"auto\",\n",
    "            \"memory_efficient\": available_memory_gb < 16\n",
    "        }\n",
    "        \n",
    "        return optimizations\n",
    "    \n",
    "    return {}\n",
    "\n",
    "# Apply optimizations if on Apple Silicon\n",
    "apple_optimizations = optimize_for_apple_silicon()\n",
    "\n",
    "# Store optimization settings for later use\n",
    "if apple_optimizations:\n",
    "    print(f\"‚úÖ Applied {len(apple_optimizations)} Apple Silicon optimizations\")\n",
    "    # These settings can be used later in model loading and batch processing\n",
    "    TTS_CONFIG.update(apple_optimizations)\n",
    "\n",
    "# Device-specific performance tips\n",
    "if device == \"mps\":\n",
    "    print(\"\\nüöÄ Apple Silicon Performance Tips:\")\n",
    "    print(\"   ‚Ä¢ Close other memory-intensive apps\")\n",
    "    print(\"   ‚Ä¢ Use smaller batch sizes if you encounter memory issues\")\n",
    "    print(\"   ‚Ä¢ MPS fallback to CPU is automatic if needed\")\n",
    "elif device == \"cuda\":\n",
    "    print(\"\\nüöÄ NVIDIA GPU Performance Tips:\")\n",
    "    print(\"   ‚Ä¢ Monitor GPU memory usage\")\n",
    "    print(\"   ‚Ä¢ Use mixed precision for faster inference\")\n",
    "elif device == \"cpu\":\n",
    "    print(\"\\nüöÄ CPU Performance Tips:\")\n",
    "    print(\"   ‚Ä¢ Consider using a GPU for faster processing\")\n",
    "    print(\"   ‚Ä¢ Process smaller text chunks to avoid memory issues\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "995a83ee",
   "metadata": {},
   "source": [
    "## 3. Prepare Tourist Guide Content\n",
    "\n",
    "Structure and format tourist guide text content, including location descriptions, historical facts, and visitor information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a592acef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tourist Guide Content Structure\n",
    "class TouristLocation:\n",
    "    def __init__(self, name, location_type, content_sections):\n",
    "        self.name = name\n",
    "        self.location_type = location_type  # monument, museum, park, restaurant, etc.\n",
    "        self.content_sections = content_sections\n",
    "        self.audio_duration = None\n",
    "        self.audio_file_path = None\n",
    "    \n",
    "    def get_full_script(self):\n",
    "        \"\"\"Combine all content sections into a complete script\"\"\"\n",
    "        script_parts = []\n",
    "        \n",
    "        # Add introduction\n",
    "        if \"introduction\" in self.content_sections:\n",
    "            script_parts.append(self.content_sections[\"introduction\"])\n",
    "        \n",
    "        # Add main description\n",
    "        if \"description\" in self.content_sections:\n",
    "            script_parts.append(self.content_sections[\"description\"])\n",
    "        \n",
    "        # Add historical information\n",
    "        if \"history\" in self.content_sections:\n",
    "            script_parts.append(f\"Here's some historical context: {self.content_sections['history']}\")\n",
    "        \n",
    "        # Add practical information\n",
    "        if \"practical_info\" in self.content_sections:\n",
    "            script_parts.append(f\"Visitor information: {self.content_sections['practical_info']}\")\n",
    "        \n",
    "        # Add conclusion\n",
    "        if \"conclusion\" in self.content_sections:\n",
    "            script_parts.append(self.content_sections[\"conclusion\"])\n",
    "        \n",
    "        # Join with appropriate pauses\n",
    "        return \" ... \".join(script_parts)\n",
    "    \n",
    "    def to_dict(self):\n",
    "        \"\"\"Convert to dictionary for JSON serialization\"\"\"\n",
    "        return {\n",
    "            \"name\": self.name,\n",
    "            \"location_type\": self.location_type,\n",
    "            \"content_sections\": self.content_sections,\n",
    "            \"audio_duration\": self.audio_duration,\n",
    "            \"audio_file_path\": self.audio_file_path\n",
    "        }\n",
    "\n",
    "# Sample tourist locations for testing\n",
    "sample_locations = [\n",
    "    TouristLocation(\n",
    "        name=\"Statue of Liberty\",\n",
    "        location_type=\"monument\",\n",
    "        content_sections={\n",
    "            \"introduction\": \"Welcome to the Statue of Liberty, one of New York's most iconic landmarks.\",\n",
    "            \"description\": \"Standing at 305 feet tall, this magnificent copper statue represents freedom and democracy. The statue depicts Libertas, the Roman goddess of liberty, holding a torch and a tablet inscribed with the date of American independence.\",\n",
    "            \"history\": \"The statue was a gift from France to the United States in 1886, designed by Fr√©d√©ric Auguste Bartholdi. It served as a beacon of hope for millions of immigrants arriving in New York Harbor.\",\n",
    "            \"practical_info\": \"Ferries depart from Battery Park every 30 minutes. Advance reservations are recommended, especially for crown access. The statue is open daily except December 25th.\",\n",
    "            \"conclusion\": \"Take your time to appreciate this symbol of freedom and the incredible views of New York Harbor.\"\n",
    "        }\n",
    "    ),\n",
    "    TouristLocation(\n",
    "        name=\"Central Park\",\n",
    "        location_type=\"park\",\n",
    "        content_sections={\n",
    "            \"introduction\": \"You're now entering Central Park, Manhattan's green oasis spanning 843 acres.\",\n",
    "            \"description\": \"This urban park features rolling meadows, tranquil lakes, and winding paths. You'll find iconic spots like Bethesda Fountain, Strawberry Fields, and the Central Park Zoo.\",\n",
    "            \"history\": \"Designed by Frederick Law Olmsted and Calvert Vaux in the 1850s, Central Park was the first landscaped public park in the United States.\",\n",
    "            \"practical_info\": \"The park is open from 6 AM to 1 AM daily. Bike rentals are available at several locations. Free walking tours are offered on weekends.\",\n",
    "            \"conclusion\": \"Enjoy your stroll through this beautiful park and don't forget to visit the famous landmarks along the way.\"\n",
    "        }\n",
    "    )\n",
    "]\n",
    "\n",
    "print(f\"‚úÖ Created {len(sample_locations)} sample tourist locations\")\n",
    "for location in sample_locations:\n",
    "    print(f\"   ‚Ä¢ {location.name} ({location.location_type})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c29e9324",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preview the full script for a location\n",
    "preview_location = sample_locations[0]\n",
    "script = preview_location.get_full_script()\n",
    "\n",
    "print(f\"üìù Full script for {preview_location.name}:\")\n",
    "print(\"=\" * 60)\n",
    "print(script)\n",
    "print(\"=\" * 60)\n",
    "print(f\"Script length: {len(script)} characters\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35262ac2",
   "metadata": {},
   "source": [
    "## 4. Generate Audio for Single Location\n",
    "\n",
    "Convert text content for a single tourist location into speech audio, with appropriate pacing and emphasis for guide narration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "837dfb13",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_location_audio(location, tts_system, method=\"bark\"):\n",
    "    \"\"\"Generate audio for a single tourist location\"\"\"\n",
    "    print(f\"üéôÔ∏è Generating audio for: {location.name}\")\n",
    "    \n",
    "    # Get the complete script\n",
    "    script = location.get_full_script()\n",
    "    \n",
    "    try:\n",
    "        # Generate speech\n",
    "        audio_arr, sampling_rate = tts_system.generate_speech(script, method=method)\n",
    "        \n",
    "        # Calculate duration\n",
    "        duration = len(audio_arr) / sampling_rate\n",
    "        location.audio_duration = duration\n",
    "        \n",
    "        print(f\"‚úÖ Audio generated successfully\")\n",
    "        print(f\"   Duration: {duration:.1f} seconds\")\n",
    "        print(f\"   Sampling rate: {sampling_rate} Hz\")\n",
    "        print(f\"   Audio shape: {audio_arr.shape}\")\n",
    "        \n",
    "        return audio_arr, sampling_rate\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error generating audio: {e}\")\n",
    "        return None, None\n",
    "\n",
    "def audio_to_segment(audio_arr, sampling_rate):\n",
    "    \"\"\"Convert numpy array to pydub AudioSegment\"\"\"\n",
    "    # Ensure audio is in the right format\n",
    "    if audio_arr.dtype != np.int16:\n",
    "        # Normalize and convert to 16-bit PCM\n",
    "        audio_arr = audio_arr / np.max(np.abs(audio_arr))  # Normalize to [-1, 1]\n",
    "        audio_arr = (audio_arr * 32767).astype(np.int16)\n",
    "    \n",
    "    # Create audio segment\n",
    "    audio_segment = AudioSegment(\n",
    "        audio_arr.tobytes(),\n",
    "        frame_rate=sampling_rate,\n",
    "        sample_width=2,  # 16-bit = 2 bytes\n",
    "        channels=1\n",
    "    )\n",
    "    \n",
    "    return audio_segment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7843e90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test audio generation for the first location\n",
    "if model_loaded:\n",
    "    test_location = sample_locations[0]\n",
    "    audio_data, sample_rate = generate_location_audio(test_location, tts_system, method=current_tts_method)\n",
    "    \n",
    "    if audio_data is not None:\n",
    "        # Display audio player\n",
    "        display(Audio(audio_data, rate=sample_rate))\n",
    "        \n",
    "        # Convert to AudioSegment for further processing\n",
    "        audio_segment = audio_to_segment(audio_data, sample_rate)\n",
    "        print(f\"üìä Audio segment created: {len(audio_segment)}ms duration\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è No TTS model loaded. Please check the model loading section above.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a69c219",
   "metadata": {},
   "source": [
    "## 5. Batch Process Multiple Locations\n",
    "\n",
    "Process multiple tourist locations in batch, generating individual audio files for each location with consistent voice and quality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f347abda",
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_process_locations(locations, tts_system, method=\"bark\", output_dir=\"./tourist_guides\"):\n",
    "    \"\"\"Process multiple locations and generate audio files with device-aware optimization\"\"\"\n",
    "    # Create output directory\n",
    "    output_path = Path(output_dir)\n",
    "    output_path.mkdir(exist_ok=True)\n",
    "    \n",
    "    results = []\n",
    "    failed_locations = []\n",
    "    \n",
    "    print(f\"üéµ Starting batch processing of {len(locations)} locations...\")\n",
    "    print(f\"üìÅ Output directory: {output_path.absolute()}\")\n",
    "    print(f\"üîß Using device: {tts_system.device}\")\n",
    "    \n",
    "    # Device-specific memory management\n",
    "    def clear_device_cache():\n",
    "        \"\"\"Clear device cache based on current device\"\"\"\n",
    "        if tts_system.device == \"cuda\":\n",
    "            torch.cuda.empty_cache()\n",
    "        elif tts_system.device == \"mps\":\n",
    "            torch.backends.mps.empty_cache()\n",
    "        # CPU doesn't need cache clearing\n",
    "    \n",
    "    for i, location in enumerate(tqdm(locations, desc=\"Processing locations\")):\n",
    "        try:\n",
    "            # Clear cache before each location for memory efficiency\n",
    "            clear_device_cache()\n",
    "            \n",
    "            # Generate audio\n",
    "            audio_data, sample_rate = generate_location_audio(location, tts_system, method=method)\n",
    "            \n",
    "            if audio_data is not None:\n",
    "                # Convert to AudioSegment\n",
    "                audio_segment = audio_to_segment(audio_data, sample_rate)\n",
    "                \n",
    "                # Create filename\n",
    "                safe_name = \"\".join(c for c in location.name if c.isalnum() or c in (' ', '-', '_')).rstrip()\n",
    "                safe_name = safe_name.replace(' ', '_')\n",
    "                filename = f\"{i+1:02d}_{safe_name}.wav\"\n",
    "                filepath = output_path / filename\n",
    "                \n",
    "                # Save audio file\n",
    "                audio_segment.export(filepath, format=\"wav\")\n",
    "                location.audio_file_path = str(filepath)\n",
    "                \n",
    "                results.append({\n",
    "                    \"location\": location.name,\n",
    "                    \"status\": \"success\",\n",
    "                    \"file_path\": str(filepath),\n",
    "                    \"duration\": location.audio_duration,\n",
    "                    \"file_size_mb\": filepath.stat().st_size / (1024 * 1024),\n",
    "                    \"device_used\": tts_system.device\n",
    "                })\n",
    "                \n",
    "                print(f\"‚úÖ {location.name}: {location.audio_duration:.1f}s ‚Üí {filename}\")\n",
    "            else:\n",
    "                failed_locations.append(location.name)\n",
    "                results.append({\n",
    "                    \"location\": location.name,\n",
    "                    \"status\": \"failed\",\n",
    "                    \"error\": \"Audio generation failed\",\n",
    "                    \"device_used\": tts_system.device\n",
    "                })\n",
    "                \n",
    "        except Exception as e:\n",
    "            # Handle device-specific errors\n",
    "            error_msg = str(e)\n",
    "            if \"mps\" in error_msg.lower() or \"metal\" in error_msg.lower():\n",
    "                error_msg += \" (MPS/Metal issue - try reducing batch size)\"\n",
    "            elif \"cuda\" in error_msg.lower() or \"memory\" in error_msg.lower():\n",
    "                error_msg += \" (GPU memory issue - try smaller models)\"\n",
    "            \n",
    "            failed_locations.append(location.name)\n",
    "            results.append({\n",
    "                \"location\": location.name,\n",
    "                \"status\": \"failed\",\n",
    "                \"error\": error_msg,\n",
    "                \"device_used\": tts_system.device\n",
    "            })\n",
    "            print(f\"‚ùå {location.name}: {error_msg}\")\n",
    "            \n",
    "            # Clear cache after errors\n",
    "            clear_device_cache()\n",
    "    \n",
    "    # Final cache cleanup\n",
    "    clear_device_cache()\n",
    "    \n",
    "    # Summary\n",
    "    successful = len([r for r in results if r[\"status\"] == \"success\"])\n",
    "    print(f\"\\nüìä Batch processing complete:\")\n",
    "    print(f\"   ‚úÖ Successful: {successful}/{len(locations)}\")\n",
    "    print(f\"   ‚ùå Failed: {len(failed_locations)}\")\n",
    "    print(f\"   üîß Device used: {tts_system.device}\")\n",
    "    \n",
    "    if failed_locations:\n",
    "        print(f\"   Failed locations: {', '.join(failed_locations)}\")\n",
    "    \n",
    "    return results, output_path\n",
    "\n",
    "# Run batch processing if model is loaded\n",
    "if model_loaded:\n",
    "    batch_results, output_directory = batch_process_locations(\n",
    "        sample_locations, \n",
    "        tts_system, \n",
    "        method=current_tts_method\n",
    "    )\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è Skipping batch processing - no TTS model loaded\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f9245a9",
   "metadata": {},
   "source": [
    "## 6. Audio Post-processing and Enhancement\n",
    "\n",
    "Apply audio enhancements such as normalization, noise reduction, and adding background music or ambient sounds suitable for tourist guides."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b2f85b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def enhance_audio_for_tourism(audio_segment, enhancement_options=None):\n",
    "    \"\"\"Apply enhancements to make audio suitable for tourist guides\"\"\"\n",
    "    if enhancement_options is None:\n",
    "        enhancement_options = {\n",
    "            \"normalize\": True,\n",
    "            \"compress\": True,\n",
    "            \"add_silence\": True,\n",
    "            \"fade_in_out\": True\n",
    "        }\n",
    "    \n",
    "    enhanced = audio_segment\n",
    "    \n",
    "    print(f\"üéõÔ∏è Enhancing audio ({len(enhanced)}ms)...\")\n",
    "    \n",
    "    # Add silence at beginning and end for smooth playback\n",
    "    if enhancement_options.get(\"add_silence\", True):\n",
    "        silence_start = AudioSegment.silent(duration=500)  # 0.5 seconds\n",
    "        silence_end = AudioSegment.silent(duration=1000)   # 1 second\n",
    "        enhanced = silence_start + enhanced + silence_end\n",
    "        print(\"   ‚úÖ Added silence padding\")\n",
    "    \n",
    "    # Normalize audio levels\n",
    "    if enhancement_options.get(\"normalize\", True):\n",
    "        enhanced = normalize(enhanced)\n",
    "        print(\"   ‚úÖ Normalized audio levels\")\n",
    "    \n",
    "    # Apply gentle compression for consistent volume\n",
    "    if enhancement_options.get(\"compress\", True):\n",
    "        enhanced = compress_dynamic_range(enhanced, threshold=-20.0, ratio=2.0)\n",
    "        print(\"   ‚úÖ Applied dynamic range compression\")\n",
    "    \n",
    "    # Add fade in/out for professional sound\n",
    "    if enhancement_options.get(\"fade_in_out\", True):\n",
    "        enhanced = enhanced.fade_in(300).fade_out(500)\n",
    "        print(\"   ‚úÖ Added fade in/out\")\n",
    "    \n",
    "    print(f\"   üìä Final duration: {len(enhanced)}ms\")\n",
    "    return enhanced\n",
    "\n",
    "def add_background_ambience(speech_audio, ambience_type=\"subtle\", volume_reduction=-20):\n",
    "    \"\"\"Add subtle background ambience for tourism context\"\"\"\n",
    "    # For now, we'll create simple background tones\n",
    "    # In practice, you might load actual ambient sound files\n",
    "    \n",
    "    if ambience_type == \"subtle\":\n",
    "        # Create very quiet background tone\n",
    "        duration = len(speech_audio)\n",
    "        # Generate a quiet sine wave as placeholder\n",
    "        from pydub.generators import Sine\n",
    "        background = Sine(220).to_audio_segment(duration=duration)  # A3 note\n",
    "        background = background + volume_reduction  # Make it very quiet\n",
    "        \n",
    "        # Mix with speech (speech dominates)\n",
    "        mixed = speech_audio.overlay(background)\n",
    "        print(f\"   üéµ Added subtle background ambience\")\n",
    "        return mixed\n",
    "    \n",
    "    return speech_audio\n",
    "\n",
    "# Test enhancement on a sample if we have audio\n",
    "if model_loaded and 'audio_segment' in locals():\n",
    "    print(\"Testing audio enhancement...\")\n",
    "    \n",
    "    # Original audio info\n",
    "    print(f\"Original audio: {len(audio_segment)}ms, {audio_segment.dBFS:.1f} dBFS\")\n",
    "    \n",
    "    # Enhance the audio\n",
    "    enhanced_audio = enhance_audio_for_tourism(audio_segment)\n",
    "    \n",
    "    # Display both original and enhanced\n",
    "    print(\"\\nüéß Original audio:\")\n",
    "    display(Audio(audio_segment.get_array_of_samples(), rate=audio_segment.frame_rate))\n",
    "    \n",
    "    print(\"\\nüéß Enhanced audio:\")\n",
    "    display(Audio(enhanced_audio.get_array_of_samples(), rate=enhanced_audio.frame_rate))\n",
    "    \n",
    "    print(f\"\\nEnhanced audio: {len(enhanced_audio)}ms, {enhanced_audio.dBFS:.1f} dBFS\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è No audio available for enhancement testing\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2873d681",
   "metadata": {},
   "source": [
    "## 7. Export Audio Files with Metadata\n",
    "\n",
    "Save processed audio files with proper naming conventions and metadata including location names, duration, and guide information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "670d64a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def export_enhanced_guide(location, audio_segment, output_dir=\"./enhanced_guides\", metadata=None):\n",
    "    \"\"\"Export enhanced audio with metadata\"\"\"\n",
    "    output_path = Path(output_dir)\n",
    "    output_path.mkdir(exist_ok=True)\n",
    "    \n",
    "    # Create safe filename\n",
    "    safe_name = \"\".join(c for c in location.name if c.isalnum() or c in (' ', '-', '_')).rstrip()\n",
    "    safe_name = safe_name.replace(' ', '_')\n",
    "    \n",
    "    # Export in multiple formats\n",
    "    exports = {}\n",
    "    \n",
    "    # High quality WAV for archival\n",
    "    wav_path = output_path / f\"{safe_name}_guide.wav\"\n",
    "    audio_segment.export(wav_path, format=\"wav\")\n",
    "    exports[\"wav\"] = wav_path\n",
    "    \n",
    "    # Compressed MP3 for mobile apps\n",
    "    mp3_path = output_path / f\"{safe_name}_guide.mp3\"\n",
    "    audio_segment.export(mp3_path, format=\"mp3\", bitrate=\"128k\")\n",
    "    exports[\"mp3\"] = mp3_path\n",
    "    \n",
    "    # Create metadata file\n",
    "    metadata_info = {\n",
    "        \"location_name\": location.name,\n",
    "        \"location_type\": location.location_type,\n",
    "        \"duration_seconds\": len(audio_segment) / 1000,\n",
    "        \"duration_formatted\": f\"{len(audio_segment) // 60000}:{(len(audio_segment) % 60000) // 1000:02d}\",\n",
    "        \"file_size_mb\": {\n",
    "            \"wav\": wav_path.stat().st_size / (1024 * 1024),\n",
    "            \"mp3\": mp3_path.stat().st_size / (1024 * 1024)\n",
    "        },\n",
    "        \"created_date\": datetime.now().isoformat(),\n",
    "        \"content_sections\": list(location.content_sections.keys()),\n",
    "        \"script_length_chars\": len(location.get_full_script()),\n",
    "        \"audio_format\": {\n",
    "            \"sample_rate\": audio_segment.frame_rate,\n",
    "            \"channels\": audio_segment.channels,\n",
    "            \"sample_width\": audio_segment.sample_width\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    if metadata:\n",
    "        metadata_info.update(metadata)\n",
    "    \n",
    "    # Save metadata as JSON\n",
    "    metadata_path = output_path / f\"{safe_name}_metadata.json\"\n",
    "    with open(metadata_path, 'w', encoding='utf-8') as f:\n",
    "        json.dump(metadata_info, f, indent=2, ensure_ascii=False)\n",
    "    \n",
    "    exports[\"metadata\"] = metadata_path\n",
    "    \n",
    "    return exports, metadata_info\n",
    "\n",
    "def create_guide_collection_index(locations, output_dir=\"./enhanced_guides\"):\n",
    "    \"\"\"Create an index file for the entire guide collection\"\"\"\n",
    "    output_path = Path(output_dir)\n",
    "    \n",
    "    collection_info = {\n",
    "        \"collection_name\": \"Tourist Guide Audio Collection\",\n",
    "        \"created_date\": datetime.now().isoformat(),\n",
    "        \"total_locations\": len(locations),\n",
    "        \"total_duration_seconds\": sum(loc.audio_duration or 0 for loc in locations),\n",
    "        \"locations\": []\n",
    "    }\n",
    "    \n",
    "    for location in locations:\n",
    "        location_info = {\n",
    "            \"name\": location.name,\n",
    "            \"type\": location.location_type,\n",
    "            \"duration\": location.audio_duration,\n",
    "            \"audio_file\": location.audio_file_path\n",
    "        }\n",
    "        collection_info[\"locations\"].append(location_info)\n",
    "    \n",
    "    # Format total duration\n",
    "    total_seconds = collection_info[\"total_duration_seconds\"]\n",
    "    minutes = int(total_seconds // 60)\n",
    "    seconds = int(total_seconds % 60)\n",
    "    collection_info[\"total_duration_formatted\"] = f\"{minutes}:{seconds:02d}\"\n",
    "    \n",
    "    # Save collection index\n",
    "    index_path = output_path / \"collection_index.json\"\n",
    "    with open(index_path, 'w', encoding='utf-8') as f:\n",
    "        json.dump(collection_info, f, indent=2, ensure_ascii=False)\n",
    "    \n",
    "    return index_path, collection_info\n",
    "\n",
    "# Demo export if we have enhanced audio\n",
    "if model_loaded and 'enhanced_audio' in locals():\n",
    "    print(\"üöÄ Exporting enhanced guide with metadata...\")\n",
    "    \n",
    "    test_location = sample_locations[0]\n",
    "    exports, metadata = export_enhanced_guide(\n",
    "        test_location, \n",
    "        enhanced_audio,\n",
    "        metadata={\"tts_model\": current_tts_method, \"enhanced\": True}\n",
    "    )\n",
    "    \n",
    "    print(f\"\\nüìÅ Files exported:\")\n",
    "    for format_type, path in exports.items():\n",
    "        size_mb = path.stat().st_size / (1024 * 1024) if path.exists() else 0\n",
    "        print(f\"   {format_type.upper()}: {path.name} ({size_mb:.2f} MB)\")\n",
    "    \n",
    "    print(f\"\\nüìä Guide statistics:\")\n",
    "    print(f\"   Duration: {metadata['duration_formatted']}\")\n",
    "    print(f\"   Script length: {metadata['script_length_chars']} characters\")\n",
    "    print(f\"   Content sections: {', '.join(metadata['content_sections'])}\")\n",
    "    \n",
    "    # Create collection index\n",
    "    index_path, collection_info = create_guide_collection_index(sample_locations)\n",
    "    print(f\"\\nüìã Collection index created: {index_path.name}\")\n",
    "    print(f\"   Total locations: {collection_info['total_locations']}\")\n",
    "    print(f\"   Total duration: {collection_info['total_duration_formatted']}\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è No enhanced audio available for export demo\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0d14f75",
   "metadata": {},
   "source": [
    "## Next Steps and Extensions\n",
    "\n",
    "This notebook provides a foundation for creating tourist guide audio content. Here are some suggestions for extending the workflow:\n",
    "\n",
    "### üåç **Multilingual Support**\n",
    "- Add support for multiple languages\n",
    "- Implement language-specific TTS models\n",
    "- Create multilingual metadata\n",
    "\n",
    "### üéµ **Advanced Audio Features**\n",
    "- Add real background ambient sounds (city sounds, nature, etc.)\n",
    "- Implement audio transitions between locations\n",
    "- Add music intros/outros\n",
    "\n",
    "### üì± **Mobile App Integration**\n",
    "- Generate different quality levels for different connection speeds\n",
    "- Create chunked audio for progressive loading\n",
    "- Add GPS-triggered audio cues\n",
    "\n",
    "### üß† **AI Enhancements**\n",
    "- Use AI to generate location descriptions from photos\n",
    "- Implement personalized content based on visitor interests\n",
    "- Add interactive Q&A capabilities\n",
    "\n",
    "### üìä **Analytics and Optimization**\n",
    "- Track which sections are most engaging\n",
    "- A/B test different narration styles\n",
    "- Optimize content length based on visitor behavior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdf6cf06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summary of the workflow\n",
    "print(\"üéØ Tourist Guide TTS Workflow Summary\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "if model_loaded:\n",
    "    print(f\"‚úÖ TTS Model: {current_tts_method}\")\n",
    "    print(f\"‚úÖ Sample locations: {len(sample_locations)}\")\n",
    "    \n",
    "    if 'batch_results' in locals():\n",
    "        successful_count = len([r for r in batch_results if r[\"status\"] == \"success\"])\n",
    "        print(f\"‚úÖ Batch processing: {successful_count}/{len(sample_locations)} successful\")\n",
    "    \n",
    "    if 'enhanced_audio' in locals():\n",
    "        print(f\"‚úÖ Audio enhancement: Completed\")\n",
    "    \n",
    "    if 'exports' in locals():\n",
    "        print(f\"‚úÖ Export formats: {', '.join(exports.keys())}\")\n",
    "        \n",
    "    print(\"\\nüöÄ Ready for production use!\")\n",
    "    print(\"   You can now add more locations and scale up the generation.\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è No TTS models loaded\")\n",
    "    print(\"   Please check the model loading section and install required dependencies.\")\n",
    "\n",
    "print(\"\\nüìö Next steps:\")\n",
    "print(\"   1. Add more tourist locations to the sample_locations list\")\n",
    "print(\"   2. Customize voice settings and enhancement options\")\n",
    "print(\"   3. Implement multilingual support\")\n",
    "print(\"   4. Add background ambient sounds\")\n",
    "print(\"   5. Integrate with mobile app or web platform\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c91e595c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Device-Specific Troubleshooting and Performance Monitoring\n",
    "def check_device_status():\n",
    "    \"\"\"Check device status and provide troubleshooting information\"\"\"\n",
    "    print(\"üîç Device Status Check\")\n",
    "    print(\"=\" * 40)\n",
    "    \n",
    "    # General PyTorch info\n",
    "    print(f\"PyTorch version: {torch.__version__}\")\n",
    "    print(f\"Current device: {device}\")\n",
    "    \n",
    "    if device == \"cuda\":\n",
    "        print(f\"\\nüöÄ NVIDIA GPU Information:\")\n",
    "        print(f\"   GPU Name: {torch.cuda.get_device_name(0)}\")\n",
    "        print(f\"   GPU Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB\")\n",
    "        print(f\"   Memory Allocated: {torch.cuda.memory_allocated() / 1e9:.2f} GB\")\n",
    "        print(f\"   Memory Cached: {torch.cuda.memory_reserved() / 1e9:.2f} GB\")\n",
    "        \n",
    "    elif device == \"mps\":\n",
    "        print(f\"\\nüçé Apple Silicon Information:\")\n",
    "        print(f\"   MPS Available: {torch.backends.mps.is_available()}\")\n",
    "        print(f\"   MPS Built: {torch.backends.mps.is_built()}\")\n",
    "        \n",
    "        # System memory info\n",
    "        memory = psutil.virtual_memory()\n",
    "        print(f\"   System Memory: {memory.total / 1e9:.1f} GB\")\n",
    "        print(f\"   Available Memory: {memory.available / 1e9:.1f} GB\")\n",
    "        print(f\"   Memory Usage: {memory.percent}%\")\n",
    "        \n",
    "        # Apple Silicon specific recommendations\n",
    "        print(f\"\\nüí° Apple Silicon Tips:\")\n",
    "        if memory.available / 1e9 < 4:\n",
    "            print(\"   ‚ö†Ô∏è Low memory - consider closing other apps\")\n",
    "        print(\"   ‚Ä¢ Use Safari instead of Chrome to save memory\")\n",
    "        print(\"   ‚Ä¢ Close unnecessary applications\")\n",
    "        print(\"   ‚Ä¢ Monitor Activity Monitor for memory pressure\")\n",
    "        \n",
    "    elif device == \"cpu\":\n",
    "        print(f\"\\nüíª CPU Information:\")\n",
    "        print(f\"   CPU Cores: {psutil.cpu_count()} physical, {psutil.cpu_count(logical=False)} logical\")\n",
    "        print(f\"   CPU Usage: {psutil.cpu_percent()}%\")\n",
    "        print(f\"   Available Memory: {psutil.virtual_memory().available / 1e9:.1f} GB\")\n",
    "        \n",
    "        print(f\"\\nüí° CPU Optimization Tips:\")\n",
    "        print(\"   ‚Ä¢ Consider using a GPU for faster processing\")\n",
    "        print(\"   ‚Ä¢ Process one location at a time to avoid memory issues\")\n",
    "        print(\"   ‚Ä¢ Use Google TTS as a lightweight alternative\")\n",
    "\n",
    "def monitor_performance():\n",
    "    \"\"\"Monitor performance during processing\"\"\"\n",
    "    import time\n",
    "    \n",
    "    start_time = time.time()\n",
    "    \n",
    "    def get_performance_stats():\n",
    "        stats = {\n",
    "            \"elapsed_time\": time.time() - start_time,\n",
    "            \"cpu_percent\": psutil.cpu_percent(),\n",
    "            \"memory_percent\": psutil.virtual_memory().percent,\n",
    "            \"memory_available_gb\": psutil.virtual_memory().available / 1e9\n",
    "        }\n",
    "        \n",
    "        if device == \"cuda\":\n",
    "            stats.update({\n",
    "                \"gpu_memory_allocated_gb\": torch.cuda.memory_allocated() / 1e9,\n",
    "                \"gpu_memory_cached_gb\": torch.cuda.memory_reserved() / 1e9\n",
    "            })\n",
    "        \n",
    "        return stats\n",
    "    \n",
    "    return get_performance_stats\n",
    "\n",
    "# Run device status check\n",
    "check_device_status()\n",
    "\n",
    "# Initialize performance monitor\n",
    "perf_monitor = monitor_performance()\n",
    "\n",
    "print(f\"\\n‚úÖ System ready for TTS processing on {device}\")\n",
    "if device == \"mps\":\n",
    "    print(\"üçé Apple Silicon detected - optimizations applied\")\n",
    "elif device == \"cuda\":\n",
    "    print(\"üöÄ NVIDIA GPU detected - high performance mode\")\n",
    "else:\n",
    "    print(\"üíª CPU mode - consider GPU for better performance\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
